# 龙芯杯文档

> 2021/6/11
>
> 我们选择的架构：MIPS指令集+顺序双发处理器

<br>

### 参考资料

1. [超标量处理器设计](materials/超标量处理器.pdf)
2. [19年龙芯杯清华队决赛报告](materials/19年龙芯杯清华队决赛报告.pdf)
3. 复旦大学`FDU1.1`队在第四届“龙芯杯”的[参赛作品](https://github.com/NSCSCC-2020-Fudan/FDU1.1-NSCSCC/)
4. 薛振梁助教的`PPT`：[ICS Final Project Topics](materials\ICS Final Project Topics.pdf)、[RAM on FPGA](materials\ram-on-fpga.pdf)
5. 谭一凡助教写的`labs`：[github网页](https://github.com/Tan-YiFan/ICS-2021Spring-FDU/tree/test_linux)

<br>

### 阅读须知

- 此文档是我们小组正在参加的“龙芯杯”比赛的文档，后续会进一步更新
- 黄色标记部分表明此处还有待进一步完善
- 实现细节中相对复杂的策略单独列了一个**策略栏**来阐释

<br>

### ==器件名称表==

| 缩写   | 全称                         | 意思           | 作用                           |
| ------ | ---------------------------- | -------------- | ------------------------------ |
| BIT    | Branch Instruction Table     | 分支指令表     | 用PC预测是否是分支指令         |
| BTB    | Branch Target Buffer         | 跳转地址缓存   | 预测跳转的地址                 |
| RAS    | Return Address Stack         | 返回地址栈     | 充当函数调用和返回的硬件栈     |
| ICache | Instruction Cache            | 指令Cache      | 缓存内存到CPU的指令            |
| DCache | Data Cache                   | 数据Cache      | 缓存内存到CPU的数据            |
| FU     | functional unit              | 计算单元       | 在执行阶段计算数据             |
| CPU    | central processing unit      | 中央处理器     | 处理所有的指令                 |
| TLB    | translation lookaside buffer | 转移后备缓冲区 | 缓存虚拟地址和其映射的物理地址 |

<br>

## 总体架构

目前的架构：CPU为九级流水线

### CPU架构

与Cache的交互只在取指和访存两个阶段。

1. 取指（1）：将计算好的PC发给ICache
2. 取指（2）：获取ICache中的指令组和其它信息
3. 译码：对指令进行译码，并对分支指令的地址进行计算
4. 发射：往队列尾部插入指令组，在头部根据控制逻辑发射一条或两条指令
5. 数据获取：通过寄存器堆和数据旁路获取数据
6. 执行：用`FU`计算数据
7. 访存（1）：向DCache发送访存请求，延迟取数据
8. 访存（2）：获取DCache中的数据或其它信息，延迟计算
9. 退休：将数据写回到寄存器堆



#### 取指

- 取指分为两个阶段，第一个阶段向ICache发送地址，在第二个阶段接受指令，因为指令传来需要一定时间，所以只对传来的指令进行简单的处理和判断。
- 第一个阶段发送的数据：指令地址PC、地址有效位`valid`
- 以ICache返回的 `addr_ok` 作为是否接受到的标志，若未接收到，需继续发送数据
- 根据当前的PC值，用预测下一个PC值，并把是否预测跳转以及跳转的地址传给后续的阶段来判断分支跳转是否正确，并以此更新分支预测模块。
- 第二个阶段传来的数据：指令组中的指令、指令组的有效位 `data_ok`、指令的有效位（三位）、指令是否是分支指令`is_branch`（三位、需要ICache预解码）
- 返回的指令组64字节对齐，一般情况为一条或者两条指令；若其中有分支指令但是没有延迟槽取上，则把延迟槽也取上；若延迟槽不在同一个cache line则不取了，不会跨cache line取指。
- 发射队列三个写端口，让发射队列读写的频率尽量匹配。
- 利用ICache传来的信息可以进行简单判断以下的错误：非分支指令但预测跳转

##### 分支预测

- `BIT`和`BTB`只对预测性比较好的指令进行预测
- 对于`jr`等预测性很差的指令默认不是跳转指令
- 用 `RAS` 来处理函数调用（`jal`、`bal`）和函数返回（`jr ra`）

#### 译码

- 判断指令的类型，以及源寄存器和目的寄存器的下标，放入到发射队列中

若有跳转指令

- 按照PC相对跳转指令进行地址的计算，同时判断跳转指令的类型，并以此判断可能的分支预测错误：
- 若为PC相对跳转指令（`bne`、`j`、`jal`、`bgez`）则可以判断以下错误：一定跳转的分支指令预测不跳转（`j`）、地址预测错误、
- 若为寄存器绝对跳转（`jr`），则可以判断以下错误：一定跳转的分支指令预测不跳转、若是
- 若是函数调用则压入硬件栈，函数返回则弹出硬件栈（带计数器和返回地址所在寄存器的下标）
- 同时还要根据跳转指令的位置来对应取延迟槽的指令：若跳转指令为指令组的最后一项，即延迟槽没有取出来，则需要把当前分支指令的相关数据放在一个缓存中，等延迟槽来的时候再利用，即此时把延迟槽的指令看成分支指令，同时更新分支预测模块。

#### 发射

- 三个写端口、两个读端口的FIFO的双发队列，用head和tail下标的方式模拟队列。
- 存放的数据：指令的地址、指令的各类操作数、是否为访存指令、是否为特权指令、是否为分支指令、是否预测跳转、预测跳转的地址
- 以下不能同时发射两条指令的情况：
- 两条连续的乘除法指令：只有一个乘法器和除法器
- 访存指令：只有一个访存单元，而且DCache只有一个读写端口，没法同时处理两条访存指令
- `CP0`、`TLB`等特权指令
- 两条指令有数据相关：注意0号寄存器的假相关性（0号寄存器一直为零）
- 第二条为分支指令：分支指令和延迟槽必须一起发射，方便后续分支预测的判断。

#### 数据获取

- 用两条指令的源寄存器下标获取源寄存器里的值，同时进行旁路（转发）从而获得所有的操作数
- 寄存器堆有四个读端口、两个写端口

#### 执行

- 获得可能的转发数据，生成指令的结果，计算访存地址
- 对于分支指令，这里可以正确判断是否跳转以及跳转的地址，并更新分支预测模块。
- 多周期指令会暂停流水线

#### 访存

- 访存有两个阶段，和取指阶段类似
- 第一个阶段会发送的数据：地址有效位、是否为写请求、四位字节写使能、读写的地址、写入的数据
- 以 `Dache` 返回的 `addr_ok` 作为成功接收的标志
- 同时第一个阶段还会处理异常，并进行部分指令的延迟取数据
- 第二个阶段接受的信号：有效位 `data_ok` 和数据
- 同时第二个阶段还会进行部分指令的延迟计算

#### 退休

- 将数据写回到寄存器堆中



### 总线接口

> [参考网址](https://github.com/NSCSCC-2020-Fudan/FDU1.1-NSCSCC/tree/master/cache)



### ==Cache架构==





### 权衡与选择

1. 在哪个阶段读取寄存器的数据，需要额外的一个阶段吗？目前是增加了一个读操作数的周期专门用来读寄存器

2. 取指时分支指令与延迟槽怎么处理？（1）ICache给的指令组中分支和延迟槽绑定，问题：分支和延迟槽不在同一个cache line而且延迟槽cache miss（2）译码阶段若发现没有取到分支指令后的延迟槽，需要把分支的信息放在一个缓存中，等到下一周期取来了延迟槽再进行分支预测及其错误判断（3）折中的一个方法：当分支和延迟槽在同一个cache line时确保他们绑定，否则采取（2）中的方法。

3. 发射阶段若发射指令组第二条分支指令是否可以发射的优劣？

   



<br>

### 实现细节

#### ICache

- 组相连结构、流水线Cache、多端口读取（Mult-banking）、预解码、硬件预取、victim Cache、伪LRU替换策略
- Cache布局图：详见拓展资料（Cache布局图）
- 取值方式：两种方式，目前倾向于用第一种：（1）每次从当前地址开始往后取满一个cacheline，判断逻辑在流水线阶段完成（详见流水线取指逻辑）（2）从当前地址开始往后取两条或三条指令，取决于第二条指令是否是分支指令

- 一个cacheline中有跳转指令：若该指令跳转，则延迟槽之后的指令不应该执行
- cacheline最后一条指令为跳转指令：则必须取完下一条cacheline后再判断分支指令，用流水线控制逻辑处理
- ==cacheline有两条分支指令==
- 其它细节问题：每周期只能访问一个cacheline

#### 分支预测器

- 完整的分支预测：详见拓展资料（完整的分支预测）
- 折中的分支预测：分支预测只针对间接跳转指令（寄存器跳转），其它跳转指令（Call、return或PC直接跳转）在接收到ICache返回的指令后快速进行判断。
- 其它的细节问题：（1）BIT和CPHT数量的差别：与跳转指令的占比有关（2）由于BIT的存在，BTB不设置tag，所以不会缺失（除了一开始的强制缺失）

#### 发射队列

- 双队列交叠（考虑了硬件，其实没必要）、两个读端口和几个写端口
- ==几个写端口==：不管怎么样，都需要用控制逻辑处理分支指令和延迟槽的问题。（1）四个写端口：紧凑但是浪费硬件（~~其实无所谓~~，咱们写代码的），因为后续的双发是瓶颈（2）三个写端口：双队列交叠可能就不方便了，专门处理MIPS指令中的分支指令+延迟槽（19年清华大学队）（3）两个写端口：朴实无华（20年复旦大学队）
- 发射队列怎么判断哪些位置是有效的：==用索引或有效位遍历==
- 队列满：流水线暂停或当前指令重取

#### DCache

- 组相连结构、流水线、==单端口读写==、回写（write back）、写缓存（write buffer）、victim cache、伪LRU替换策略
- 根据 MIPS标准要求，对于不同段的访存，数据缓存行为不同：（1）**kseg3/ksseg** 按 TLB 判断是否经过缓存（2）**kseg1** 不经过缓存（3）**kseg0** 可由 CP0 ConfigK0 寄存器控制，MIPS 标准中这一行为的实现可选（4）**useg** 按 TLB 判断是否经过缓存
- 单端口读写：只有一个访存单元，而且这样可以简化DCache的逻辑，~~当然写Cache的人想多端口也没问题~~​​，这样就需要两个访存单元了
- 采用回写策略（write back）：脏数据被替换的时候才写回
- 写缓存（write buffer）：写回时写到缓存中，等总线空闲的时候再写缓存再写到内存中，不过Cache缺失时，需要先在写缓存里找，判断是否在其中。
- 流水线访问：先写后读冲突，用Delayed Store Addr和Delayed Store Data寄存器解决，类似于转发

#### Store Buffer

- 这个器件跟整体的设计有关，如果能保证执行阶段store正确性的话可以不要
- store指令计算完后放在这里，直到退休（retire）才真正写回DCache，这样的话load指令需要先从Store Buffer里找对应的指令

#### L2 Cache

- 单端口

#### 乘除法器件

- 一个乘法器和一个除法器（考虑到MIPS乘除法指令之间会有移动Hi、Lo的指令，所以不太可能两条乘/除法连在一起），若连续两条乘除法指令，则只发射第一条

#### 访存FU

- 设置一个（连续两条指令为load的可能性很小，没有必要为此增加大量的硬件），若同时有两条load指令，则只发射第一条。

#### 硬件栈

- RAS(Return Address Stack)：带计数器的栈，解决自己调用自己的递归问题。

#### ==数据旁路==

- ScoreBoard

#### ==寄存器文件==

- 四个读端口、两个写端口、Hi和Lo寄存器（特判）

#### ==TLB==

<br>

### 策略

##### ==组相联结构==

##### 预解码（pre-code）

- 解释：ICache获取内存的数据的时，判断其是否是分支指令，并将结果另外保存在ICache中

##### 流水线Cache

- 解释：像流水线一样处理Cache，降低时钟频率

  ![对DCache的写操作使用流水线](资料图片\对DCache的写操作使用流水线.PNG)

##### victim cache

> 《超标量处理器设计》2.2.4

- 解释：防止被踢出的数据马上被利用，而与之相对的Filter Cache则是防止不会再用的数据一直不被踢出

![victimcache所处的位置](资料图片\victimcache所处的位置.PNG)

##### 预取（prefetching）

> 《超标量处理器设计》2.2.5

- 解释：字如其名，提前把额外的数据（当前Cacheline的下几条Cacheline等将来可能会用到的）取好

- ICache效果比DCache要好，DCache可以不使用预取

- 为了防止预取的数据没有用造成“Cache 污染”，可以将预取的指令放到单独的一个缓存（Stream Buffer）中。（Alpha 21064对指令预取使用的方法）

  ![对指令采用硬件预取](资料图片\对指令采用硬件预取.PNG)

##### ScoreBoard

> 《超标量处理器设计》1.3.1

- 解释：用来转发、旁路的表格，保存正在计算的寄存器相关数据在哪里
- P：Pending，表示结果还没有写回到寄存器中
- F：在那个FU中执行，转发时会用到这个信息
- Result Position：记录到达FU流水线的哪个阶段，每个周期右移一位，不同指令的转发条件不同。

![一个典型的ScoreBoard](资料图片\一个典型的ScoreBoard.PNG)

##### 伪LRU替换

> 《超标量处理器设计》2.1.3

- 解释：LRU（least recently used），把最晚使用的Cacheline替换出去

![伪LRU算法的工作流程](资料图片\伪LRU算法的工作流程.PNG)

##### 交叠实现多端口

- 是一种思想
- 实现：简单的说就是一整块东西拆成多块，然后不同的块可以同时输出，而不用真的在一块上实现多端口。
- 考虑硬件：通常的多端口需要大量资源，交叠可以节省硬件资源（~~不过对于我们来说没啥用~~）
- 可以应用的部件：ICache、发射队列、寄存器文件等等



### 拓展资料

#### 完整的分支预测

> Alpha 21264

在取指阶段预测该指令：

1. 是否是分支指令：用PC的部分索引BIT（branch instruction table）                 （1）是否是CALL指令（jal、bal）：利用BTB（branch target buffer）中存放的额外信息，若是，则把当前PC+8的值（有延迟槽）压入带计数器的RAS（Return Address Stack）（2）是否是Return（jr）：利用BTB中存放额外信息，若是，把RAS中的栈顶元素作为预测的地址

2. 是否会跳转：采用竞争的分支预测（1）GHR（global history register）：记录所有跳转指令的跳转情况（2）BHT（branch history table）：记录局部跳转指令的跳转情况（3）PHTs（pattern history table）：两位的**饱和计数器**表格（4）CPHT（choice PHT）：根据PC和GHR里的值来选择使用哪一个分支预测的结果。

3. 跳转的地址：存放在BTB中

   > 《超标量处理器设计》4.2.5

   ![竞争的分支预测](资料图片\竞争的分支预测.PNG)

数据的更新：用预测的结果更新GHR，在分支指令退休的时候更新BHR和PHT中的饱和计数器



#### Cache布局图：

> 2020年龙芯杯复旦大学`FDU1.1`队

![Cache设计图-复旦大学FDU1.1队](资料图片\Cache设计图-复旦大学FDU1.1队.PNG)

<br>

### 龙芯杯常见问题

1. 龙芯杯的top文件需要自己写吗？

> 本学期的top文件实例化了一个龙芯杯的top，可以参考那个。

2. 双发流水线如何进行golden trace的比对？
3. 操作系统进程切换的时候需要我们保存处理器状态吗？



<br>

### 其它部分

#### 指令集

- 需要实现的指令: [普通部分](materials\指令集.md)、[外设部分](materials\支持操作系统的额外指令.md)
- CLO和CLZ可以共用一套硬件电路，但是就不能同时处理两条指令了

#### ==自动化==

- 自动化测试和部署：GitLab CI 

<br>

